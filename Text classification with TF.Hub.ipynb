{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.0.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.7.0\n",
      "GPU is NOT available\n"
     ]
    }
   ],
   "source": [
    "# So the idea here is to do the word embedding \n",
    "# using a pre-trained model provided by TF Hub\n",
    "# which is similar to Docker hub for models\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "!pip install -q tensorflow-hub\n",
    "!pip install -q tensorflow-datasets\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Make sure tf version is 2 otherwise shit will break!\n",
    "# Also, I'm running this on Python3\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_split = tfds.Split.TRAIN.subsplit([6, 4])\n",
    "\n",
    "(train_data, validation_data), test_data = tfds.load(\n",
    "    name=\"imdb_reviews\",\n",
    "    split=(train_validation_split, tfds.Split.TEST),\n",
    "    as_supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
    "train_examples_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=220, shape=(10,), dtype=int64, numpy=array([1, 1, 1, 1, 1, 1, 0, 1, 1, 0])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=400, shape=(3, 20), dtype=float32, numpy=\n",
       "array([[ 3.9819887 , -4.4838037 ,  5.177359  , -2.3643482 , -3.2938678 ,\n",
       "        -3.5364532 , -2.4786978 ,  2.5525482 ,  6.688532  , -2.3076782 ,\n",
       "        -1.9807833 ,  1.1315885 , -3.0339816 , -0.7604128 , -5.743445  ,\n",
       "         3.4242578 ,  4.790099  , -4.03061   , -5.992149  , -1.7297493 ],\n",
       "       [ 3.4232912 , -4.230874  ,  4.1488533 , -0.29553518, -6.802391  ,\n",
       "        -2.5163853 , -4.4002395 ,  1.905792  ,  4.7512794 , -0.40538004,\n",
       "        -4.3401685 ,  1.0361497 ,  0.9744097 ,  0.71507156, -6.2657013 ,\n",
       "         0.16533905,  4.560262  , -1.3106939 , -3.1121316 , -2.1338716 ],\n",
       "       [ 3.8508697 , -5.003031  ,  4.8700504 , -0.04324996, -5.893603  ,\n",
       "        -5.2983093 , -4.004676  ,  4.1236343 ,  6.267754  ,  0.11632943,\n",
       "        -3.5934832 ,  0.8023905 ,  0.56146765,  0.9192484 , -7.3066816 ,\n",
       "         2.8202746 ,  6.2000837 , -3.5709393 , -4.564525  , -2.305622  ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n",
    "hub_layer(train_examples_batch[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 400,373\n",
      "Trainable params: 400,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 4s 136ms/step - loss: 0.7021 - accuracy: 0.5762 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 3s 111ms/step - loss: 0.6250 - accuracy: 0.6561 - val_loss: 0.6078 - val_accuracy: 0.6710\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 3s 113ms/step - loss: 0.5902 - accuracy: 0.6962 - val_loss: 0.5786 - val_accuracy: 0.7006\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 3s 115ms/step - loss: 0.5566 - accuracy: 0.7247 - val_loss: 0.5507 - val_accuracy: 0.7254\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 3s 113ms/step - loss: 0.5270 - accuracy: 0.7516 - val_loss: 0.5216 - val_accuracy: 0.7516\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 4s 118ms/step - loss: 0.4942 - accuracy: 0.7774 - val_loss: 0.4906 - val_accuracy: 0.7730\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 4s 117ms/step - loss: 0.4524 - accuracy: 0.7988 - val_loss: 0.4609 - val_accuracy: 0.7899\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 3s 113ms/step - loss: 0.4191 - accuracy: 0.8215 - val_loss: 0.4326 - val_accuracy: 0.8071\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 3s 113ms/step - loss: 0.3867 - accuracy: 0.8402 - val_loss: 0.4080 - val_accuracy: 0.8200\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 3s 115ms/step - loss: 0.3574 - accuracy: 0.8573 - val_loss: 0.3859 - val_accuracy: 0.8308\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 3s 113ms/step - loss: 0.3306 - accuracy: 0.8687 - val_loss: 0.3682 - val_accuracy: 0.8404\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 4s 117ms/step - loss: 0.3082 - accuracy: 0.8807 - val_loss: 0.3531 - val_accuracy: 0.8470\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 3s 112ms/step - loss: 0.2840 - accuracy: 0.8893 - val_loss: 0.3416 - val_accuracy: 0.8524\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 3s 114ms/step - loss: 0.2686 - accuracy: 0.8989 - val_loss: 0.3315 - val_accuracy: 0.8589\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 3s 116ms/step - loss: 0.2473 - accuracy: 0.9061 - val_loss: 0.3242 - val_accuracy: 0.8608\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 3s 116ms/step - loss: 0.2315 - accuracy: 0.9144 - val_loss: 0.3171 - val_accuracy: 0.8636\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 4s 125ms/step - loss: 0.2175 - accuracy: 0.9209 - val_loss: 0.3122 - val_accuracy: 0.8675\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2053 - accuracy: 0.9273 - val_loss: 0.3093 - val_accuracy: 0.8684\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 4s 117ms/step - loss: 0.1932 - accuracy: 0.9333 - val_loss: 0.3057 - val_accuracy: 0.8696\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 3s 114ms/step - loss: 0.1811 - accuracy: 0.9373 - val_loss: 0.3052 - val_accuracy: 0.8713\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data.shuffle(10000).batch(512), \n",
    "    epochs=20, \n",
    "    validation_data=validation_data.batch(512),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 - 2s - loss: 0.3247 - accuracy: 0.8596\n",
      "loss: 0.325\n",
      "accuracy: 0.860\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data.batch(512), verbose=2)\n",
    "\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(\"%s: %.3f\" % (name, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
